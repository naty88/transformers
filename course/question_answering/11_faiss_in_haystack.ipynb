{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS With Haystack\n",
    "\n",
    "FAISS is unfortunately **not** presently supported on Windows, so if you are on Windows then you will need to stick with Elasticsearch. If you have access to Linux or Mac then continue.\n",
    "\n",
    "We'll be using Haystack again, so fortunately setup is very straight-forward. We first import and initialize a FAISS document store using a very similiar logic to what we used before - but this time we will be storing the FAISS index locally.\n",
    "\n",
    "Storing the index locally means that we will need two files, a SQLite database, and the FAISS index. We create the FAISS index later, but we create the SQLite database on initialization.\n",
    "\n",
    "We will store both in the `models` directory, but adjust this to your own needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '../../models/faiss'\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install 'farm-haystack[faiss]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we include this path within a SQLite database location string in the following document store initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/deepset-ai/haystack/issues/2450#issuecomment-1108254740\n",
    "from haystack.document_stores.faiss import FAISSDocumentStore\n",
    "\n",
    "# initialize FAISS\n",
    "document_store = FAISSDocumentStore(\n",
    "    faiss_index_factory_str='Flat',\n",
    "    sql_url=f'sqlite:///{path}/squad_dev.db',\n",
    "    return_embedding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our validation data from file, which we will be adding to the FAISS index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../../data/squad/dev.json', 'r') as f:\n",
    "    squad = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Data\n",
    "\n",
    "As we saw with Elasticsearch, our current FAISS index has been initialized but contains nothing. Now we need to populate the index with our *dev.json* data. \n",
    "\n",
    "This time, we'll be making use of the Haystack `Document` object. Which we import with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from haystack import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object prepares our data into the correct object format for our document stores - which in this case is FAISS.\n",
    "\n",
    "As before where we had a dictionary with two keys `'content'` and `'meta'`, the *Document* object provides two corresponding arguments, `content` and `meta`. So rather than using the format we used before which looked like:\n",
    "\n",
    "```json\n",
    "{\n",
    "    'content': '<document text here>',\n",
    "    'meta': {\n",
    "        'other': '<other info here>'\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "We will be using this *Document* object format instead:\n",
    "\n",
    "```python\n",
    "Document(\n",
    "    content='<document text here>',\n",
    "    meta={\n",
    "        'other': '<other info here>'\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "Just like before, we will be feeding these *Document* objects into a list, which we will then feed into our FAISS `write_documents` method. Remember, our dataset contains duplicate contexts, so we must remove them first using `list(set(...))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create list of contexts\n",
    "contexts = [sample['context'] for sample in squad]\n",
    "\n",
    "# remove duplicates\n",
    "contexts = list(set(contexts))\n",
    "\n",
    "# create list of Document objects\n",
    "squad_docs = [Document(content=sample) for sample in contexts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, because we're storing our FAISS index on file, we may find (if running this script more than once) that we first need to delete any documents that already exist in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document_store.delete_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add the data to the index just like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddc50cf4bd645f79a5e54739a5d1d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing Documents:   0%|          | 0/1204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.write_documents(squad_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way that our documents are indexed will depend on the embedding model being used by our retriever. So, we need to initialize our DPR model (the retriever), and then `update_embeddings` using this retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26dd1f7e96946e5ad6b3fc9226a4ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating Embedding:   0%|          | 0/1204 [00:00<?, ? docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/1216 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model='facebook/dpr-question_encoder-single-nq-base',\n",
    "    passage_embedding_model='facebook/dpr-ctx_encoder-single-nq-base',\n",
    "    use_gpu=True,\n",
    "    embed_title=True\n",
    ")\n",
    "\n",
    "document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've fully prepared our document store, we can save it. We will save to the same location we saved our SQLite database, but this time we will be using the *.faiss* filetype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document_store.save(f'{path}/squad_dev.faiss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our FAISS index is now saved to file! We'll go ahead and delete the `document_store` and `retriever`, and try reinitializing both using the data we've saved to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del document_store, retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we do now is apply the `load` method directly from `FAISSDocumentStore`, including both the FAISS index location, and SQLite database location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document_store = FAISSDocumentStore.load(index_path=f'{path}/squad_dev.faiss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can re-initialize our retriever, using the same arguments as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model='facebook/dpr-question_encoder-single-nq-base',\n",
    "    passage_embedding_model='facebook/dpr-ctx_encoder-single-nq-base',\n",
    "    use_gpu=True,\n",
    "    embed_title=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can begin retrieving relevant contexts to our questions using `retriever.retrieve`, which requires a single argument, `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Document: {'content': \"A Turing machine is a mathematical model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, but rather as a thought experiment representing a computing machine—anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church–Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a RAM machine, Conway's Game of Life, cellular automata or any programming language can be computed on a Turing machine. Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the Turing machine is the most commonly used model in complexity theory.\", 'content_type': 'text', 'score': 0.662629665750177, 'meta': {'vector_id': '966'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': 'd2a8a5add2c09df16a63ed3c34c1d46'}>,\n",
       " <Document: {'content': 'Philosophers in antiquity used the concept of force in the study of stationary and moving objects and simple machines, but thinkers such as Aristotle and Archimedes retained fundamental errors in understanding force. In part this was due to an incomplete understanding of the sometimes non-obvious force of friction, and a consequently inadequate view of the nature of natural motion. A fundamental error was the belief that a force is required to maintain motion, even at a constant velocity. Most of the previous misunderstandings about motion and force were eventually corrected by Galileo Galilei and Sir Isaac Newton. With his mathematical insight, Sir Isaac Newton formulated laws of motion that were not improved-on for nearly three hundred years. By the early 20th century, Einstein developed a theory of relativity that correctly predicted the action of forces on objects with increasing momenta near the speed of light, and also provided insight into the forces produced by gravitation and inertia.', 'content_type': 'text', 'score': 0.6604814308381923, 'meta': {'vector_id': '1058'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': 'e380b9fefa3259906817a9e049656e6d'}>,\n",
       " <Document: {'content': 'When considering computational problems, a problem instance is a string over an alphabet. Usually, the alphabet is taken to be the binary alphabet (i.e., the set {0,1}), and thus the strings are bitstrings. As in a real-world computer, mathematical objects other than bitstrings must be suitably encoded. For example, integers can be represented in binary notation, and graphs can be encoded directly via their adjacency matrices, or by encoding their adjacency lists in binary.', 'content_type': 'text', 'score': 0.6599062945780403, 'meta': {'vector_id': '533'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '78c55f4499bca1760cc3684cb553c933'}>,\n",
       " <Document: {'content': 'Closely related fields in theoretical computer science are analysis of algorithms and computability theory. A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem. More precisely, it tries to classify problems that can or cannot be solved with appropriately restricted resources. In turn, imposing restrictions on the available resources is what distinguishes computational complexity from computability theory: the latter theory asks what kind of problems can, in principle, be solved algorithmically.', 'content_type': 'text', 'score': 0.6594243665033994, 'meta': {'vector_id': '254'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '42b3e25793765b085da634955c175f98'}>,\n",
       " <Document: {'content': 'Aristotle provided a philosophical discussion of the concept of a force as an integral part of Aristotelian cosmology. In Aristotle\\'s view, the terrestrial sphere contained four elements that come to rest at different \"natural places\" therein. Aristotle believed that motionless objects on Earth, those composed mostly of the elements earth and water, to be in their natural place on the ground and that they will stay that way if left alone. He distinguished between the innate tendency of objects to find their \"natural place\" (e.g., for heavy bodies to fall), which led to \"natural motion\", and unnatural or forced motion, which required continued application of a force. This theory, based on the everyday experience of how objects move, such as the constant application of a force needed to keep a cart moving, had conceptual trouble accounting for the behavior of projectiles, such as the flight of arrows. The place where the archer moves the projectile was at the start of the flight, and while the projectile sailed through the air, no discernible efficient cause acts on it. Aristotle was aware of this problem and proposed that the air displaced through the projectile\\'s path carries the projectile to its target. This explanation demands a continuum like air for change of place in general.', 'content_type': 'text', 'score': 0.6593342167122263, 'meta': {'vector_id': '832'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': 'b5f33e199c1cf8845f617d48d4e71988'}>,\n",
       " <Document: {'content': 'The notion \"force\" keeps its meaning in quantum mechanics, though one is now dealing with operators instead of classical variables and though the physics is now described by the Schrödinger equation instead of Newtonian equations. This has the consequence that the results of a measurement are now sometimes \"quantized\", i.e. they appear in discrete portions. This is, of course, difficult to imagine in the context of \"forces\". However, the potentials V(x,y,z) or fields, from which the forces generally can be derived, are treated similar to classical position variables, i.e., .', 'content_type': 'text', 'score': 0.6585025516639957, 'meta': {'vector_id': '930'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': 'cac0630683bf55c6f3a0968e92e79710'}>,\n",
       " <Document: {'content': 'In 1846, the natural history lectures of Louis Agassiz were acclaimed both in New York and on the campus at Harvard College. Agassiz\\'s approach was distinctly idealist and posited Americans\\' \"participation in the Divine Nature\" and the possibility of understanding \"intellectual existences\". Agassiz\\'s perspective on science combined observation with intuition and the assumption that a person can grasp the \"divine plan\" in all phenomena. When it came to explaining life-forms, Agassiz resorted to matters of shape based on a presumed archetype for his evidence. This dual view of knowledge was in concert with the teachings of Common Sense Realism derived from Scottish philosophers Thomas Reid and Dugald Stewart, whose works were part of the Harvard curriculum at the time. The popularity of Agassiz\\'s efforts to \"soar with Plato\" probably also derived from other writings to which Harvard students were exposed, including Platonic treatises by Ralph Cudworth, John Norrisand, in a Romantic vein, Samuel Coleridge. The library records at Harvard reveal that the writings of Plato and his early modern and Romantic followers were almost as regularly read during the 19th century as those of the \"official philosophy\" of the more empirical and more deistic Scottish school.', 'content_type': 'text', 'score': 0.6580667051494249, 'meta': {'vector_id': '860'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': 'bce97dd824fbe02d1d01c4c76deca66f'}>,\n",
       " <Document: {'content': 'The origin of electric and magnetic fields would not be fully explained until 1864 when James Clerk Maxwell unified a number of earlier theories into a set of 20 scalar equations, which were later reformulated into 4 vector equations by Oliver Heaviside and Josiah Willard Gibbs. These \"Maxwell Equations\" fully described the sources of the fields as being stationary and moving charges, and the interactions of the fields themselves. This led Maxwell to discover that electric and magnetic fields could be \"self-generating\" through a wave that traveled at a speed that he calculated to be the speed of light. This insight united the nascent fields of electromagnetic theory with optics and led directly to a complete description of the electromagnetic spectrum.', 'content_type': 'text', 'score': 0.6576824150664343, 'meta': {'vector_id': '578'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '82d4c7724584e0d25197782b072974de'}>,\n",
       " <Document: {'content': 'Computational complexity theory is a branch of the theory of computation in theoretical computer science that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm.', 'content_type': 'text', 'score': 0.6567578407834961, 'meta': {'vector_id': '1120'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': 'ef80756dc751af204203f664fa56b1d4'}>,\n",
       " <Document: {'content': 'The development of fundamental theories for forces proceeded along the lines of unification of disparate ideas. For example, Isaac Newton unified the force responsible for objects falling at the surface of the Earth with the force responsible for the orbits of celestial mechanics in his universal theory of gravitation. Michael Faraday and James Clerk Maxwell demonstrated that electric and magnetic forces were unified through one consistent theory of electromagnetism. In the 20th century, the development of quantum mechanics led to a modern understanding that the first three fundamental forces (all except gravity) are manifestations of matter (fermions) interacting by exchanging virtual particles called gauge bosons. This standard model of particle physics posits a similarity between the forces and led scientists to predict the unification of the weak and electromagnetic forces in electroweak theory subsequently confirmed by observation. The complete formulation of the standard model predicts an as yet unobserved Higgs mechanism, but observations such as neutrino oscillations indicate that the standard model is incomplete. A Grand Unified Theory allowing for the combination of the electroweak interaction with the strong force is held out as a possibility with candidate theories such as supersymmetry proposed to accommodate some of the outstanding unsolved problems in physics. Physicists are still attempting to develop self-consistent unification models that would combine all four fundamental interactions into a theory of everything. Einstein tried and failed at this endeavor, but currently the most popular approach to answering this question is string theory.:212–219', 'content_type': 'text', 'score': 0.655960049707232, 'meta': {'vector_id': '992'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': 'd75f0925dca88d80bc176c8e6ac99de'}>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.retrieve('What subject is most abstract?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we've extracted a few contexts stored within FAISS, that our DPR model believes answers our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
